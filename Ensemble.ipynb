{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.4\n",
      "1.0.1.post2\n",
      "0.2.2\n"
     ]
    }
   ],
   "source": [
    "# import some libraries you maybe use\n",
    "import torchvision # an useful library to help I/O (highly recommend). To install this, just do \"pip install torchvision\"\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "import os\n",
    "import visdom\n",
    "import scipy\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/ensemble_mp_mel/result.csv\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = './results'\n",
    "TRAINING_NAME = 'ensemble_mp_mel'\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, TRAINING_NAME)\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR, 'weight.pth')\n",
    "RESULT_PATH = os.path.join(OUTPUT_DIR, 'result.csv')\n",
    "print(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing\n",
    "In order to train the model with training data, the first step is to read the data from your folder, database, etc. The below is just an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torchvision.transforms import Compose, ToTensor, Grayscale, Resize, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "# Define path to your dataset\n",
    "dataset = \"./data\" # the root folder\n",
    "trainpath = os.path.join(dataset,\"train\") # train set\n",
    "valpath = os.path.join(dataset,\"val\") # validation set\n",
    "\n",
    "cut = lambda x: x[:11025]\n",
    "norm =  lambda x: x.astype(np.float32) / np.max(x)\n",
    "spct = lambda x: scipy.signal.spectrogram(x ,fs= 10e3,mode='magnitude')[2]\n",
    "tri = lambda x: [x, x, x]\n",
    "totensor = lambda x: torch.Tensor(x)\n",
    "\n",
    "tsfm = Compose([\n",
    "        cut, # rescale to -1 to 1\n",
    "        norm, # rescale to -1 to 1\n",
    "        spct, # MFCC \n",
    "        tri,\n",
    "        totensor\n",
    "        ])\n",
    "\n",
    "\n",
    "nploader = np.load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = DatasetFolder(root=trainpath, loader=nploader, transform=tsfm, extensions=['npy'])\n",
    "valdata = DatasetFolder(root=valpath, loader=nploader, transform=tsfm, extensions=['npy'])\n",
    "\n",
    "# Create a loader\n",
    "trainloader = DataLoader(traindata,batch_size=batch_size,shuffle=True, pin_memory=True, num_workers=6)\n",
    "valloader = DataLoader(valdata,batch_size=batch_size,shuffle=True,  pin_memory=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frog1', 'Frog2', 'Frog3', 'Grylloidea1', 'Grylloidea2', 'Tettigonioidea1', 'Tettigonioidea2', 'drums_FloorTom', 'drums_HiHat', 'drums_Kick', 'drums_MidTom', 'drums_Ride', 'drums_Rim', 'drums_SmallTom', 'drums_Snare', 'guitar_3rd_fret', 'guitar_7th_fret', 'guitar_9th_fret', 'guitar_chord1', 'guitar_chord2']\n",
      "{'Frog1': 0, 'Frog2': 1, 'Frog3': 2, 'Grylloidea1': 3, 'Grylloidea2': 4, 'Tettigonioidea1': 5, 'Tettigonioidea2': 6, 'drums_FloorTom': 7, 'drums_HiHat': 8, 'drums_Kick': 9, 'drums_MidTom': 10, 'drums_Ride': 11, 'drums_Rim': 12, 'drums_SmallTom': 13, 'drums_Snare': 14, 'guitar_3rd_fret': 15, 'guitar_7th_fret': 16, 'guitar_9th_fret': 17, 'guitar_chord1': 18, 'guitar_chord2': 19}\n"
     ]
    }
   ],
   "source": [
    "print(traindata.classes) # show all classes\n",
    "print(traindata.class_to_idx) # show the mapping from class to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Frog1', 1: 'Frog2', 2: 'Frog3', 3: 'Grylloidea1', 4: 'Grylloidea2', 5: 'Tettigonioidea1', 6: 'Tettigonioidea2', 7: 'drums_FloorTom', 8: 'drums_HiHat', 9: 'drums_Kick', 10: 'drums_MidTom', 11: 'drums_Ride', 12: 'drums_Rim', 13: 'drums_SmallTom', 14: 'drums_Snare', 15: 'guitar_3rd_fret', 16: 'guitar_7th_fret', 17: 'guitar_9th_fret', 18: 'guitar_chord1', 19: 'guitar_chord2'}\n"
     ]
    }
   ],
   "source": [
    "idx_to_class = {val: key for key, val in traindata.class_to_idx.items()} # build an inverse mapping for later use\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_idx2class = {9: 'Frog1', 10: 'Frog2', 19: 'Frog3', 3: 'Grylloidea1', 14: 'Grylloidea2', 0: 'Tettigonioidea1', 1: 'Tettigonioidea2', 11: 'drums_FloorTom', 5: 'drums_HiHat', 6: 'drums_Kick', 4: 'drums_MidTom', 16: 'drums_Ride', 13: 'drums_Rim', 7: 'drums_SmallTom', 2: 'drums_Snare', 15: 'guitar_3rd_fret', 12: 'guitar_7th_fret', 18: 'guitar_9th_fret', 17: 'guitar_chord1', 8: 'guitar_chord2'}\n",
    "#print(correct_idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_class2idx = {val: key for key, val in correct_idx2class.items()}\n",
    "#print(correct_class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9, 1: 10, 2: 19, 3: 3, 4: 14, 5: 0, 6: 1, 7: 11, 8: 5, 9: 6, 10: 4, 11: 16, 12: 13, 13: 7, 14: 2, 15: 15, 16: 12, 17: 18, 18: 17, 19: 8}\n"
     ]
    }
   ],
   "source": [
    "corrected_idx2idx = {val: correct_class2idx[key] for key, val in traindata.class_to_idx.items()}\n",
    "print(corrected_idx2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/ensemble_mp_melnpad_phasenormpad/result.csv\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = './results'\n",
    "TRAINING_NAME = 'ensemble_mp_melnpad_phasenormpad'\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, TRAINING_NAME)\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR, 'weight.pth')\n",
    "RESULT_PATH = os.path.join(OUTPUT_DIR, 'result.csv')\n",
    "print(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'resnet50_phase_decay_norm_pad':0.5, 'resnet50_meldata':0.5}\n",
    "ROOT_DIR = './results'\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, TRAINING_NAME)\n",
    "_NP_PATH =  os.path.join(_OUTPUT_DIR, 'raw_result.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = None\n",
    "for name in names:\n",
    "    OUTPUT_DIR = os.path.join(ROOT_DIR, name)\n",
    "    rnp = np.load(os.path.join(OUTPUT_DIR, 'raw_result.npy'))\n",
    "    if probs is None:\n",
    "        probs=nn.functional.softmax(torch.tensor(rnp), dim=1)*names[name]\n",
    "    else:\n",
    "        probs+=nn.functional.softmax(torch.tensor(rnp), dim=1)*names[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = probs.data.max(1, keepdim=True)[1].cpu().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [corrected_idx2idx[idx] for idx in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'id': list(range(0 ,len(test_data))), 'category':result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  category\n",
       "0   0        18\n",
       "1   1         2\n",
       "2   2        18\n",
       "3   3         8\n",
       "4   4         8"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(RESULT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
